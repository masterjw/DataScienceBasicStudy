{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML lab 02 - TensorFlow로 간단한 Linear Regression 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hypothesis and cost function\n",
    "$$H(x) = Wx + b $$\n",
    "$$cost(W,b)=\\frac{1}{m} \\sum_{i=1}^m ( H( x^{(i)} ) - y^{(i)} )^2$$\n",
    "* H: 가설, W: Weight, b: bias\n",
    "* 학습 : W, b를 조정하여 cost 함수를 minimize하는 것\n",
    "    * 그래서 W, b를 TensorFlow variable 이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Build graph using TF operations\n",
    "$$H(x) = Wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cost(W,b) = \\frac{1}{m} \\sum_{i=1}^m (H(x^{(i)}) - y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/ loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2~3. Run/update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6951 [ 0.21763086] [ 1.02898467]\n",
      "20 0.177041 [ 0.49136865] [ 1.0848695]\n",
      "40 0.156673 [ 0.53783649] [ 1.04381049]\n",
      "60 0.142256 [ 0.56170493] [ 0.99570048]\n",
      "80 0.129198 [ 0.58250785] [ 0.94899613]\n",
      "100 0.11734 [ 0.60214788] [ 0.90440542]\n",
      "120 0.10657 [ 0.6208474] [ 0.86190248]\n",
      "140 0.0967888 [ 0.63866633] [ 0.82139629]\n",
      "160 0.0879051 [ 0.6556477] [ 0.78279382]\n",
      "180 0.0798369 [ 0.67183089] [ 0.74600542]\n",
      "200 0.0725091 [ 0.68725371] [ 0.71094584]\n",
      "220 0.0658539 [ 0.70195168] [ 0.67753404]\n",
      "240 0.0598096 [ 0.71595877] [ 0.64569253]\n",
      "260 0.05432 [ 0.72930765] [ 0.61534733]\n",
      "280 0.0493343 [ 0.74202919] [ 0.58642828]\n",
      "300 0.0448062 [ 0.75415272] [ 0.55886835]\n",
      "320 0.0406937 [ 0.76570678] [ 0.53260356]\n",
      "340 0.0369587 [ 0.77671766] [ 0.50757313]\n",
      "360 0.0335665 [ 0.78721112] [ 0.48371908]\n",
      "380 0.0304856 [ 0.79721141] [ 0.46098608]\n",
      "400 0.0276875 [ 0.80674177] [ 0.4393214]\n",
      "420 0.0251462 [ 0.81582421] [ 0.41867489]\n",
      "440 0.0228382 [ 0.82447976] [ 0.39899874]\n",
      "460 0.020742 [ 0.83272856] [ 0.38024721]\n",
      "480 0.0188382 [ 0.84058976] [ 0.36237699]\n",
      "500 0.0171092 [ 0.84808141] [ 0.34534657]\n",
      "520 0.0155389 [ 0.85522097] [ 0.32911661]\n",
      "540 0.0141126 [ 0.86202514] [ 0.31364933]\n",
      "560 0.0128173 [ 0.86850941] [ 0.29890898]\n",
      "580 0.0116409 [ 0.87468898] [ 0.28486139]\n",
      "600 0.0105725 [ 0.88057816] [ 0.27147394]\n",
      "620 0.00960207 [ 0.88619047] [ 0.25871566]\n",
      "640 0.00872076 [ 0.89153916] [ 0.24655703]\n",
      "660 0.00792033 [ 0.89663643] [ 0.23496975]\n",
      "680 0.00719336 [ 0.90149415] [ 0.22392698]\n",
      "700 0.00653314 [ 0.90612352] [ 0.21340325]\n",
      "720 0.00593349 [ 0.9105354] [ 0.20337409]\n",
      "740 0.0053889 [ 0.91473991] [ 0.19381626]\n",
      "760 0.00489428 [ 0.91874689] [ 0.18470763]\n",
      "780 0.00444507 [ 0.92256546] [ 0.17602703]\n",
      "800 0.00403708 [ 0.92620456] [ 0.16775441]\n",
      "820 0.00366654 [ 0.92967272] [ 0.15987056]\n",
      "840 0.00333 [ 0.9329778] [ 0.15235725]\n",
      "860 0.00302438 [ 0.93612754] [ 0.145197]\n",
      "880 0.00274677 [ 0.93912947] [ 0.13837326]\n",
      "900 0.00249466 [ 0.94199014] [ 0.13187018]\n",
      "920 0.0022657 [ 0.94471633] [ 0.12567277]\n",
      "940 0.00205774 [ 0.94731444] [ 0.11976661]\n",
      "960 0.00186887 [ 0.94979054] [ 0.11413802]\n",
      "980 0.00169734 [ 0.95215017] [ 0.10877394]\n",
      "1000 0.00154155 [ 0.95439893] [ 0.10366195]\n",
      "1020 0.00140006 [ 0.95654202] [ 0.09879021]\n",
      "1040 0.00127156 [ 0.95858431] [ 0.09414745]\n",
      "1060 0.00115485 [ 0.96053076] [ 0.08972289]\n",
      "1080 0.00104885 [ 0.96238565] [ 0.08550625]\n",
      "1100 0.000952585 [ 0.96415341] [ 0.08148775]\n",
      "1120 0.000865149 [ 0.96583807] [ 0.07765812]\n",
      "1140 0.000785744 [ 0.96744359] [ 0.07400845]\n",
      "1160 0.000713628 [ 0.96897352] [ 0.07053035]\n",
      "1180 0.00064813 [ 0.97043169] [ 0.0672157]\n",
      "1200 0.000588638 [ 0.97182131] [ 0.06405678]\n",
      "1220 0.000534611 [ 0.9731456] [ 0.06104635]\n",
      "1240 0.000485542 [ 0.97440767] [ 0.05817741]\n",
      "1260 0.000440977 [ 0.97561044] [ 0.05544326]\n",
      "1280 0.000400504 [ 0.97675663] [ 0.05283761]\n",
      "1300 0.000363744 [ 0.97784901] [ 0.05035445]\n",
      "1320 0.000330358 [ 0.97889] [ 0.04798798]\n",
      "1340 0.000300039 [ 0.97988194] [ 0.04573281]\n",
      "1360 0.000272499 [ 0.98082757] [ 0.04358351]\n",
      "1380 0.000247488 [ 0.98172855] [ 0.04153524]\n",
      "1400 0.000224773 [ 0.98258722] [ 0.03958326]\n",
      "1420 0.000204141 [ 0.98340559] [ 0.037723]\n",
      "1440 0.000185405 [ 0.98418546] [ 0.03595014]\n",
      "1460 0.000168387 [ 0.98492873] [ 0.0342606]\n",
      "1480 0.000152931 [ 0.98563701] [ 0.03265046]\n",
      "1500 0.000138894 [ 0.98631197] [ 0.03111601]\n",
      "1520 0.000126146 [ 0.98695529] [ 0.02965369]\n",
      "1540 0.000114569 [ 0.98756838] [ 0.02826008]\n",
      "1560 0.000104052 [ 0.98815256] [ 0.02693195]\n",
      "1580 9.45037e-05 [ 0.98870939] [ 0.02566625]\n",
      "1600 8.58293e-05 [ 0.98923993] [ 0.02446004]\n",
      "1620 7.7951e-05 [ 0.98974574] [ 0.0233105]\n",
      "1640 7.0796e-05 [ 0.99022776] [ 0.02221492]\n",
      "1660 6.42978e-05 [ 0.99068689] [ 0.02117084]\n",
      "1680 5.83964e-05 [ 0.99112463] [ 0.02017588]\n",
      "1700 5.30362e-05 [ 0.99154174] [ 0.01922768]\n",
      "1720 4.81684e-05 [ 0.99193925] [ 0.01832403]\n",
      "1740 4.37472e-05 [ 0.99231809] [ 0.01746285]\n",
      "1760 3.97324e-05 [ 0.99267906] [ 0.01664215]\n",
      "1780 3.60852e-05 [ 0.99302316] [ 0.01586002]\n",
      "1800 3.27728e-05 [ 0.99335104] [ 0.01511467]\n",
      "1820 2.97655e-05 [ 0.99366349] [ 0.01440434]\n",
      "1840 2.7033e-05 [ 0.99396127] [ 0.01372739]\n",
      "1860 2.45513e-05 [ 0.99424511] [ 0.01308226]\n",
      "1880 2.22985e-05 [ 0.99451554] [ 0.01246746]\n",
      "1900 2.02516e-05 [ 0.99477321] [ 0.01188155]\n",
      "1920 1.83936e-05 [ 0.99501884] [ 0.01132322]\n",
      "1940 1.67048e-05 [ 0.99525303] [ 0.01079106]\n",
      "1960 1.51714e-05 [ 0.99547607] [ 0.01028393]\n",
      "1980 1.37794e-05 [ 0.99568868] [ 0.00980064]\n",
      "2000 1.25151e-05 [ 0.99589127] [ 0.00934006]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.87509 [ 1.60159743] [ 1.96938944]\n",
      "20 0.0678741 [ 0.83459073] [ 1.71091688]\n",
      "40 0.059136 [ 0.8421371] [ 1.66999722]\n",
      "60 0.051644 [ 0.85246074] [ 1.63266373]\n",
      "80 0.0451011 [ 0.86212313] [ 1.59777904]\n",
      "100 0.0393871 [ 0.87115282] [ 1.56517899]\n",
      "120 0.034397 [ 0.87959117] [ 1.53471386]\n",
      "140 0.0300392 [ 0.88747686] [ 1.5062443]\n",
      "160 0.0262334 [ 0.89484608] [ 1.47963905]\n",
      "180 0.0229099 [ 0.90173262] [ 1.45477641]\n",
      "200 0.0200073 [ 0.9081682] [ 1.4315418]\n",
      "220 0.0174726 [ 0.91418236] [ 1.40982878]\n",
      "240 0.0152589 [ 0.91980261] [ 1.38953781]\n",
      "260 0.0133257 [ 0.92505485] [ 1.37057579]\n",
      "280 0.0116375 [ 0.92996305] [ 1.35285556]\n",
      "300 0.0101631 [ 0.93454981] [ 1.33629608]\n",
      "320 0.00887548 [ 0.93883628] [ 1.32082057]\n",
      "340 0.00775103 [ 0.94284189] [ 1.30635881]\n",
      "360 0.00676903 [ 0.9465853] [ 1.29284394]\n",
      "380 0.00591144 [ 0.95008349] [ 1.28021455]\n",
      "400 0.0051625 [ 0.95335245] [ 1.26841223]\n",
      "420 0.00450847 [ 0.95640749] [ 1.25738299]\n",
      "440 0.00393728 [ 0.95926231] [ 1.2470758]\n",
      "460 0.00343847 [ 0.96193027] [ 1.2374438]\n",
      "480 0.00300282 [ 0.9644236] [ 1.22844219]\n",
      "500 0.00262238 [ 0.96675348] [ 1.22003031]\n",
      "520 0.00229015 [ 0.96893084] [ 1.21216929]\n",
      "540 0.002 [ 0.97096562] [ 1.20482326]\n",
      "560 0.00174661 [ 0.97286713] [ 1.19795811]\n",
      "580 0.00152531 [ 0.97464412] [ 1.19154251]\n",
      "600 0.00133207 [ 0.97630477] [ 1.18554747]\n",
      "620 0.0011633 [ 0.97785652] [ 1.17994475]\n",
      "640 0.00101593 [ 0.97930676] [ 1.17470932]\n",
      "660 0.000887222 [ 0.98066193] [ 1.16981661]\n",
      "680 0.000774818 [ 0.98192835] [ 1.16524434]\n",
      "700 0.000676653 [ 0.98311192] [ 1.16097128]\n",
      "720 0.000590924 [ 0.98421782] [ 1.15697837]\n",
      "740 0.000516063 [ 0.98525143] [ 1.153247]\n",
      "760 0.000450683 [ 0.98621732] [ 1.14975965]\n",
      "780 0.000393581 [ 0.98711997] [ 1.14650083]\n",
      "800 0.000343715 [ 0.98796356] [ 1.14345539]\n",
      "820 0.000300175 [ 0.98875171] [ 1.14060962]\n",
      "840 0.000262145 [ 0.98948836] [ 1.13795006]\n",
      "860 0.000228933 [ 0.99017686] [ 1.13546479]\n",
      "880 0.000199928 [ 0.99082011] [ 1.13314211]\n",
      "900 0.000174601 [ 0.99142128] [ 1.13097179]\n",
      "920 0.000152478 [ 0.99198318] [ 1.12894332]\n",
      "940 0.000133163 [ 0.99250817] [ 1.12704766]\n",
      "960 0.000116287 [ 0.9929989] [ 1.12527609]\n",
      "980 0.000101556 [ 0.99345738] [ 1.12362087]\n",
      "1000 8.86915e-05 [ 0.99388582] [ 1.12207401]\n",
      "1020 7.74567e-05 [ 0.99428618] [ 1.12062848]\n",
      "1040 6.7645e-05 [ 0.99466032] [ 1.11927772]\n",
      "1060 5.90721e-05 [ 0.99501014] [ 1.11801517]\n",
      "1080 5.15896e-05 [ 0.99533683] [ 1.11683524]\n",
      "1100 4.50539e-05 [ 0.99564224] [ 1.11573279]\n",
      "1120 3.93444e-05 [ 0.99592769] [ 1.11470246]\n",
      "1140 3.43606e-05 [ 0.99619436] [ 1.11373961]\n",
      "1160 3.00085e-05 [ 0.99644357] [ 1.11283982]\n",
      "1180 2.62067e-05 [ 0.99667645] [ 1.11199903]\n",
      "1200 2.28867e-05 [ 0.99689406] [ 1.11121333]\n",
      "1220 1.99881e-05 [ 0.99709749] [ 1.11047912]\n",
      "1240 1.74562e-05 [ 0.99728745] [ 1.10979307]\n",
      "1260 1.52449e-05 [ 0.99746507] [ 1.10915172]\n",
      "1280 1.33133e-05 [ 0.99763113] [ 1.10855234]\n",
      "1300 1.16262e-05 [ 0.99778628] [ 1.10799217]\n",
      "1320 1.01538e-05 [ 0.9979313] [ 1.10746872]\n",
      "1340 8.86771e-06 [ 0.99806672] [ 1.10697961]\n",
      "1360 7.7435e-06 [ 0.99819332] [ 1.10652244]\n",
      "1380 6.76333e-06 [ 0.99831164] [ 1.10609543]\n",
      "1400 5.90557e-06 [ 0.99842221] [ 1.1056962]\n",
      "1420 5.15759e-06 [ 0.99852556] [ 1.10532308]\n",
      "1440 4.50398e-06 [ 0.99862212] [ 1.10497451]\n",
      "1460 3.93381e-06 [ 0.99871236] [ 1.10464871]\n",
      "1480 3.43567e-06 [ 0.9987967] [ 1.10434437]\n",
      "1500 3.00033e-06 [ 0.99887544] [ 1.10405982]\n",
      "1520 2.62003e-06 [ 0.99894911] [ 1.10379398]\n",
      "1540 2.28824e-06 [ 0.99901789] [ 1.10354543]\n",
      "1560 1.99797e-06 [ 0.99908227] [ 1.10331309]\n",
      "1580 1.74495e-06 [ 0.99914241] [ 1.10309613]\n",
      "1600 1.52395e-06 [ 0.99919862] [ 1.10289335]\n",
      "1620 1.33076e-06 [ 0.99925107] [ 1.10270393]\n",
      "1640 1.16217e-06 [ 0.99930006] [ 1.1025269]\n",
      "1660 1.0153e-06 [ 0.9993459] [ 1.10236144]\n",
      "1680 8.86296e-07 [ 0.99938875] [ 1.10220671]\n",
      "1700 7.74155e-07 [ 0.99942875] [ 1.10206223]\n",
      "1720 6.76055e-07 [ 0.99946618] [ 1.10192716]\n",
      "1740 5.90499e-07 [ 0.99950111] [ 1.10180104]\n",
      "1760 5.15621e-07 [ 0.99953377] [ 1.10168302]\n",
      "1780 4.50437e-07 [ 0.99956429] [ 1.10157275]\n",
      "1800 3.93272e-07 [ 0.99959284] [ 1.10146976]\n",
      "1820 3.4341e-07 [ 0.99961954] [ 1.10137355]\n",
      "1840 2.9986e-07 [ 0.9996444] [ 1.10128343]\n",
      "1860 2.61902e-07 [ 0.9996677] [ 1.10119951]\n",
      "1880 2.28785e-07 [ 0.99968952] [ 1.10112095]\n",
      "1900 1.99782e-07 [ 0.99970978] [ 1.10104764]\n",
      "1920 1.7454e-07 [ 0.9997288] [ 1.10097897]\n",
      "1940 1.52361e-07 [ 0.99974656] [ 1.10091484]\n",
      "1960 1.33062e-07 [ 0.99976319] [ 1.10085487]\n",
      "1980 1.16204e-07 [ 0.99977869] [ 1.10079896]\n",
      "2000 1.0157e-07 [ 0.99979311] [ 1.10074687]\n"
     ]
    }
   ],
   "source": [
    "# Now we can use X and Y in place of x_data and y_data\n",
    "# # placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "# cost/ loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                           Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.09971333]\n",
      "[ 3.60022879]\n",
      "[ 2.60043526  4.60002279]\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
